# Deep-Learning-Seminar
deep learning Seminar lectured by Seonhwa Lee on Winter Semester

# 1st Seminar
## History of Artificial Neural Network and BackPropagation
Artificial Neural Network의 역사부터  Backpropagation의 동작원리까지 살펴봅니다

# 2nd Seminar
## The 7 ways improving the neural network
1. Vanishing gradeints problem
2. Xavier and He initialization
3. Non-saturating Activation Functions
4. Batch Normalization
5. Cross Entropy cost function instead of quadratic cost fuction
6. dropout
7. Regularization
8. Other ways of Optimizer
9. Practice - Classification of Mnist using MLP model

# 3rd Seminar
## Softmax Layer and Convolutional Neural Networks
1. Softmax layer
2. Basic of Convolutional Neural Network
  - Local Connectivity
  - Receptive Field
  - Spatial Arrangement
  - About zero-padding
  - parameter sharing
  - pooling layer
3. Representative models of convolutional neural network 

# 4th Seminar
## AlexNet, GoogleNet, ResNet
1. AlexNet
- main source : ImageNet Classification with Deep Convolutional Neural Networks, Krizhevsky et al, 2012
2. GoogleNet
- main source : Going Deeper with convolutions, Szegedy et al, 2014
3. ResNet
- main source : Deep residual learning for image recognition, He, et al, 2016 
