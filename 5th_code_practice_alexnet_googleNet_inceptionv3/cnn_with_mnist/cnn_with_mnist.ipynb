{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deepnn(x):\n",
    "#  \"\"\"숫자를 분류하기 위한 Deep Neural Networks 그래프를 생성한다.\"\"\"\n",
    "\n",
    "  #인자들(Args):\n",
    "   # x: (N_examples, 784) 차원을 가진 input tensor, 784 일반적인 MNIST 데이터의 픽셀 개수이다.\n",
    "  #리턴값들(Returns):\n",
    " #   tuple (y, keep_prob). y는 (N_examples, 10)형태의 숫자(0-9) tensor이다. \n",
    "#    keep_prob는 dropout을 위한 scalar placeholder이다.\n",
    "\n",
    "    # Convolutional Neural Netwokrs(CNNs)를 위한 reshape.\n",
    "  # 마지막 차원(dimension)은 특징들(\"features\")을 나타낸다.-이 코드에서는 이미지가 grayscale이라 일차원이지만, RGB 이미지라면 3차원, RGBA라면 4차원 이미지 일 것이다.\n",
    "    x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "  # 첫번째 convolutional layer - 하나의 grayscale 이미지를 32개의 특징들(feature)으로 맵핑(maping)한다.\n",
    "    W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "    b_conv1 = bias_variable([32])\n",
    "    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "\n",
    "  # Pooling layer - 2X만큼 downsample한다.\n",
    "    h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "  # 두번째 convolutional layer -- 32개의 특징들(feature)을 64개의 특징들(feature)로 맵핑(maping)한다.\n",
    "    W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "    b_conv2 = bias_variable([64])\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "\n",
    "  # 두번째 pooling layer.\n",
    "    h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "  # Fully Connected Layer 1 -- 2번의 downsampling 이후에, 우리의 28x28 이미지는 7x7x64 특징들(feature map)이 된다.\n",
    "  # 이를 1024개의 특징들로 맵핑(maping)한다.\n",
    "    W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "    b_fc1 = bias_variable([1024])\n",
    "\n",
    "    h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "    W_fc2 = weight_variable([1024, 10])\n",
    "    b_fc2 = bias_variable([10])\n",
    "\n",
    "    y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "    return y_conv, keep_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/train-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting ./mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist=input_data.read_data_sets('./mnist', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=tf.placeholder(tf.float32, [None, 784])\n",
    "y_=tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_conv, keep_prob=deepnn(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy=tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "train_step=tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction=tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy=tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.06\n",
      "step 10, training accuracy 0.34\n",
      "step 20, training accuracy 0.52\n",
      "step 30, training accuracy 0.62\n",
      "step 40, training accuracy 0.68\n",
      "step 50, training accuracy 0.68\n",
      "step 60, training accuracy 0.82\n",
      "step 70, training accuracy 0.72\n",
      "step 80, training accuracy 0.84\n",
      "step 90, training accuracy 0.9\n",
      "step 100, training accuracy 0.92\n",
      "step 110, training accuracy 0.84\n",
      "step 120, training accuracy 0.84\n",
      "step 130, training accuracy 0.84\n",
      "step 140, training accuracy 0.84\n",
      "step 150, training accuracy 0.82\n",
      "step 160, training accuracy 0.9\n",
      "step 170, training accuracy 0.8\n",
      "step 180, training accuracy 0.9\n",
      "step 190, training accuracy 0.9\n",
      "step 200, training accuracy 0.88\n",
      "step 210, training accuracy 0.88\n",
      "step 220, training accuracy 0.92\n",
      "step 230, training accuracy 0.88\n",
      "step 240, training accuracy 0.98\n",
      "step 250, training accuracy 0.96\n",
      "step 260, training accuracy 0.86\n",
      "step 270, training accuracy 0.9\n",
      "step 280, training accuracy 0.94\n",
      "step 290, training accuracy 0.9\n",
      "step 300, training accuracy 0.9\n",
      "step 310, training accuracy 0.94\n",
      "step 320, training accuracy 0.84\n",
      "step 330, training accuracy 0.92\n",
      "step 340, training accuracy 0.92\n",
      "step 350, training accuracy 0.92\n",
      "step 360, training accuracy 0.92\n",
      "step 370, training accuracy 0.92\n",
      "step 380, training accuracy 0.94\n",
      "step 390, training accuracy 0.94\n",
      "step 400, training accuracy 0.92\n",
      "step 410, training accuracy 0.88\n",
      "step 420, training accuracy 0.92\n",
      "step 430, training accuracy 0.94\n",
      "step 440, training accuracy 0.9\n",
      "step 450, training accuracy 0.88\n",
      "step 460, training accuracy 0.94\n",
      "step 470, training accuracy 0.92\n",
      "step 480, training accuracy 0.96\n",
      "step 490, training accuracy 1\n",
      "test_accuracy 0.9433\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(500):\n",
    "        batch=mnist.train.next_batch(50)\n",
    "        if i%10==0:\n",
    "            train_accuracy=accuracy.eval(feed_dict={\n",
    "                X:batch[0], y_:batch[1], keep_prob:1.0\n",
    "            })\n",
    "            print('step %d, training accuracy %g' %(i, train_accuracy))\n",
    "        train_step.run(feed_dict={X:batch[0], y_:batch[1], keep_prob:0.5})\n",
    "    \n",
    "    print('test_accuracy %g' %(accuracy.eval(feed_dict={\n",
    "        X:mnist.test.images, y_:mnist.test.labels, keep_prob:1.0})))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
